{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import movielens_data\n",
    "MovieLensDataset=movielens_data.MovieLensDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"e:\\\\seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.bert4rec import *\n",
    "from config import config  \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'e:\\seq\\data\\ml-1m'\n",
    "train_dataset = MovieLensDataset(data_dir, max_len=50, split='train')\n",
    "test_dataset = MovieLensDataset(data_dir, max_len=50, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BERT4Rec(\n",
    "        item_num=train_dataset.num_items,\n",
    "        max_len=config.max_len,\n",
    "        hidden_units=config.hidden_units,\n",
    "        num_heads=config.num_heads,\n",
    "        num_layers=config.num_layers,\n",
    "        dropout=config.dropout\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3884"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.num_items\n",
    "test_dataset.num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3884"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def compute_loss(logits, labels):\n",
    "    # logits shape: [batch_size, seq_len, vocab_size]\n",
    "    # labels shape: [batch_size, seq_len]\n",
    "    \n",
    "    # Reshape logits and labels\n",
    "    logits = logits.view(-1, logits.size(-1))  # [batch_size * seq_len, vocab_size]\n",
    "    labels = labels.view(-1)  # [batch_size * seq_len]\n",
    "    \n",
    "    # Create a mask to ignore padding tokens\n",
    "    mask = (labels > 0).float()\n",
    "    \n",
    "    # Compute cross entropy loss\n",
    "    loss = F.cross_entropy(logits, labels, reduction='none')\n",
    "    \n",
    "    # Apply mask and compute mean loss\n",
    "    loss = (loss * mask).sum() / mask.sum()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1502, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model(train_dataset[1][0].unsqueeze(0))\n",
    "lab=train_dataset[1][1].unsqueeze(0)\n",
    "compute_loss(pred,lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2546])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model(test_dataset[1][0].unsqueeze(0))\n",
    "pred=pred[:,-1,:]\n",
    "torch.argmax(pred,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:11<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@1: 0.1770, NDCG@1: 0.1770\n",
      "HR@5: 0.5061, NDCG@5: 0.3481\n",
      "HR@10: 0.6545, NDCG@10: 0.3962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def calculate_metrics_batch(model, test_dataset, batch_size=128, k_values=[1, 5, 10],device=\"cpu\"):\n",
    "    model.eval()\n",
    "    hrs = {k: [] for k in k_values}\n",
    "    ndcgs = {k: [] for k in k_values}\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            interactions, candidates, labels = batch\n",
    "            interactions = interactions.to(device)\n",
    "            candidates = candidates.to(device)\n",
    "            # 获取模型预测\n",
    "            logits = model(interactions)\n",
    "            \n",
    "            # 我们只关心最后一个时间步的预测\n",
    "            last_logits = logits[:, -1, :]\n",
    "            \n",
    "            batch_size = interactions.size(0)\n",
    "            for i in range(batch_size):\n",
    "                # 获取候选项的得分\n",
    "                candidate_scores = last_logits[i][candidates[i]]\n",
    "                \n",
    "                # 计算排序\n",
    "                _, indices = torch.sort(candidate_scores, descending=True)\n",
    "                \n",
    "                # 找到正样本的排名\n",
    "                rank = (indices == 0).nonzero().item() + 1  # +1 因为索引从0开始\n",
    "                \n",
    "                # 计算 HR 和 NDCG\n",
    "                for k in k_values:\n",
    "                    hrs[k].append(1 if rank <= k else 0)\n",
    "                    ndcgs[k].append(1 / np.log2(rank + 1) if rank <= k else 0)\n",
    "    \n",
    "    # 计算平均值\n",
    "    for k in k_values:\n",
    "        hrs[k] = np.mean(hrs[k])\n",
    "        ndcgs[k] = np.mean(ndcgs[k])\n",
    "    \n",
    "    return hrs, ndcgs\n",
    "\n",
    "# 使用示例\n",
    "model.eval()  # 确保模型处于评估模式\n",
    "hrs, ndcgs = calculate_metrics_batch(model, test_dataset)\n",
    "\n",
    "# 打印结果\n",
    "for k in hrs.keys():\n",
    "    print(f\"HR@{k}: {hrs[k]:.4f}, NDCG@{k}: {ndcgs[k]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "def train(model, train_dataset, test_dataset, device, \n",
    "          batch_size=128, num_epochs=100, lr=1e-3, \n",
    "          eval_steps=1000, patience=5, k_values=[1, 5, 10]):\n",
    "    \n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    best_hr = 0\n",
    "    best_epoch = -1\n",
    "    patience_counter = 0\n",
    "    global_step = 0\n",
    "    \n",
    "    # Save initial model\n",
    "    torch.save(model.state_dict(), 'initial_model.pth')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            interactions, labels = batch\n",
    "            interactions, labels = interactions.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(interactions)\n",
    "            loss = compute_loss(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % eval_steps == 0:\n",
    "                avg_loss = total_loss / eval_steps\n",
    "                print(f\"\\nStep {global_step}, Average Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "                # Evaluate on test set\n",
    "                hrs, ndcgs = calculate_metrics_batch(model, test_dataset, batch_size, k_values, device)\n",
    "                \n",
    "                print(\"Evaluation Results:\")\n",
    "                for k in k_values:\n",
    "                    print(f\"HR@{k}: {hrs[k]:.4f}, NDCG@{k}: {ndcgs[k]:.4f}\")\n",
    "                \n",
    "                # Check for improvement\n",
    "                if hrs[k_values[0]] > best_hr:\n",
    "                    best_hr = hrs[k_values[0]]\n",
    "                    best_epoch = epoch\n",
    "                    patience_counter = 0\n",
    "                    torch.save(model.state_dict(), 'best_model.pth')\n",
    "                    print(\"New best model saved!\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                \n",
    "                # Early stopping\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"No improvement for {patience} evaluations. Early stopping.\")\n",
    "                    break\n",
    "                \n",
    "                total_loss = 0\n",
    "                model.train()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch {epoch+1} completed in {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "    \n",
    "    print(f\"Training completed. Best HR@{k_values[0]}: {best_hr:.4f} at epoch {best_epoch+1}\")\n",
    "    \n",
    "    # Load best model if exists, otherwise keep the current model\n",
    "    if os.path.exists('best_model.pth'):\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "        print(\"Loaded the best model.\")\n",
    "    elif os.path.exists('initial_model.pth'):\n",
    "        model.load_state_dict(torch.load('initial_model.pth'))\n",
    "        print(\"No improvement during training. Loaded the initial model.\")\n",
    "    else:\n",
    "        print(\"No saved model found. Returning the current model state.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 95/95 [00:02<00:00, 40.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 2.35 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 95/95 [00:02<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed in 2.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 95/95 [00:02<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed in 2.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 95/95 [00:02<00:00, 43.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed in 2.20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 95/95 [00:02<00:00, 38.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed in 2.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 95/95 [00:02<00:00, 40.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed in 2.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 95/95 [00:02<00:00, 44.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed in 2.16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 95/95 [00:02<00:00, 44.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed in 2.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 95/95 [00:02<00:00, 42.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed in 2.24 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 95/95 [00:02<00:00, 44.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed in 2.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30:  47%|████▋     | 45/95 [00:00<00:01, 45.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1000, Average Loss: 0.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:02<00:00, 39.55it/s]\n",
      "Epoch 11/30:  58%|█████▊    | 55/95 [00:03<00:05,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "HR@1: 0.1813, NDCG@1: 0.1813\n",
      "HR@5: 0.4902, NDCG@5: 0.3418\n",
      "HR@10: 0.6381, NDCG@10: 0.3896\n",
      "New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 95/95 [00:04<00:00, 20.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed in 4.63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 95/95 [00:02<00:00, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed in 2.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 95/95 [00:02<00:00, 44.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed in 2.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 95/95 [00:02<00:00, 44.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed in 2.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 95/95 [00:02<00:00, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed in 2.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 95/95 [00:02<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed in 2.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 95/95 [00:02<00:00, 44.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed in 2.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 95/95 [00:02<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed in 2.16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 95/95 [00:02<00:00, 44.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed in 2.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 95/95 [00:02<00:00, 43.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed in 2.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 95/95 [00:02<00:00, 44.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed in 2.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30:   4%|▍         | 4/95 [00:00<00:02, 35.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2000, Average Loss: 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:02<00:00, 42.08it/s]\n",
      "Epoch 22/30:  14%|█▎        | 13/95 [00:02<00:15,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "HR@1: 0.1652, NDCG@1: 0.1652\n",
      "HR@5: 0.4960, NDCG@5: 0.3351\n",
      "HR@10: 0.6478, NDCG@10: 0.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 95/95 [00:04<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed in 4.44 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 95/95 [00:02<00:00, 45.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed in 2.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 95/95 [00:02<00:00, 44.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed in 2.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 95/95 [00:02<00:00, 44.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed in 2.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 95/95 [00:02<00:00, 44.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed in 2.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 95/95 [00:02<00:00, 44.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed in 2.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 95/95 [00:02<00:00, 44.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed in 2.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 95/95 [00:02<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed in 2.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 95/95 [00:02<00:00, 44.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed in 2.14 seconds\n",
      "Training completed. Best HR@1: 0.1813 at epoch 11\n",
      "Loaded the best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT4Rec(\n",
       "  (item_emb): Embedding(3886, 256, padding_idx=0)\n",
       "  (pos_emb): Embedding(50, 256)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=3885, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model,train_dataset,test_dataset,device=\"cuda\",batch_size=64,num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1246, 3741,  586, 1960, 2503,  454, 2848, 1569,  477,  162,  377, 3350,\n",
       "         1492,  346,   21, 1386, 3188, 2285, 1938, 2210, 1350,  643, 2359, 1514,\n",
       "         1733, 1352, 2422, 1365,  771,  164,  456, 1741, 3039, 2813,  365,  439,\n",
       "         1557, 2560, 1645, 3189,  728, 1934, 2058,  290,   94,  431, 1506, 1642,\n",
       "         1849, 3885]),\n",
       " tensor([1849, 1223, 2879,  771, 3011, 3636,  524, 3695, 2328,  552, 2648, 2297,\n",
       "         1167,   62,  976, 1371, 1643,   39,  346, 2321, 3555, 3653, 2624, 3635,\n",
       "         3002, 1213, 2072, 1392, 1550, 3399,  471,   57, 2446, 1274,  202,  377,\n",
       "         3828, 2804, 1886, 1269, 1203, 1280,  252, 1266, 2724, 2645, 2560,  494,\n",
       "          870,  908, 1120,  353, 2180,  316, 1376, 1459, 2773, 2729, 3185, 3546,\n",
       "         2400, 2791, 1523, 1827,  231, 2993, 3570,  490, 2745, 3382, 1275, 2861,\n",
       "         1943, 2883, 3631, 1065, 3489, 1879, 2004, 2960, 1655, 3033, 2702, 2723,\n",
       "         3475,  221, 1227, 2900, 2632, 2847,  585, 3117,  350,  586,  555,  590,\n",
       "         3744, 3107, 3730, 2253,   32]),\n",
       " tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
